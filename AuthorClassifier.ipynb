{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk.data\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data import Field, BucketIterator,LabelField\n",
    "from torchtext import data\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors=['Hemingway','Nietzsche','Wilde']\n",
    "authors_id=[0,1,2]\n",
    "PATH = \"/home/julia/PycharmProjects/seq2seq/books/\"\n",
    "books=[]\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "TEST_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_open(path):\n",
    "    #Remove special characters\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        #text = re.sub(r'([^a-záéíóúÁÉÍÓÚA-Z0-9,._── :?!¡¿])', '', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentences(text):\n",
    "    file_doc = nlp(text)\n",
    "    #if len(sentences)>2:\n",
    "    sentences = list(file_doc.sents)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/julia/PycharmProjects/seq2seq/books/Hemingway\n",
      "/home/julia/PycharmProjects/seq2seq/books/Nietzsche\n",
      "/home/julia/PycharmProjects/seq2seq/books/Wilde\n"
     ]
    }
   ],
   "source": [
    "### Abrir Documentos\n",
    "\n",
    "sents_by_author=[]\n",
    "for author in authors:\n",
    "    name_file = PATH + author\n",
    "    print(name_file)\n",
    "    books_author = []\n",
    "    sents = []\n",
    "    for file in glob.glob(name_file + \"/*.txt\"):\n",
    "        books_author.append(file)\n",
    "        txt = file_open(file)\n",
    "        sents = sents+convert_sentences(txt)\n",
    "    sents_by_author.append(sents)\n",
    "    #print(books_author)\n",
    "    books.append(books_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18813\n",
      "20235\n",
      "24288\n"
     ]
    }
   ],
   "source": [
    "print(len(sents_by_author[0])) #número de oraciones para Hemingway\n",
    "print(len(sents_by_author[1]))#numero de oraciones para Nietzche\n",
    "print(len(sents_by_author[2])) #número de oraciones de Wilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = []\n",
    "for i in range(len(authors)):\n",
    "    for sent in sents_by_author[i]:\n",
    "        if (len(sent)>=3):\n",
    "            row.append([sent,authors[i]])\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59407\n"
     ]
    }
   ],
   "source": [
    "print(len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(row,columns=[\"input\", 'author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59402</th>\n",
       "      <td>(At, last, !, \\n\\n)</td>\n",
       "      <td>Wilde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59403</th>\n",
       "      <td>(Lady, Bracknell, .,  )</td>\n",
       "      <td>Wilde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59404</th>\n",
       "      <td>(My, nephew, ,, you, seem, to, be, displaying,...</td>\n",
       "      <td>Wilde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59405</th>\n",
       "      <td>(Jack, .,  )</td>\n",
       "      <td>Wilde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59406</th>\n",
       "      <td>(On, the, contrary, ,, Aunt, Augusta, ,, I, 'v...</td>\n",
       "      <td>Wilde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input author\n",
       "59402                                (At, last, !, \\n\\n)  Wilde\n",
       "59403                            (Lady, Bracknell, .,  )  Wilde\n",
       "59404  (My, nephew, ,, you, seem, to, be, displaying,...  Wilde\n",
       "59405                                       (Jack, .,  )  Wilde\n",
       "59406  (On, the, contrary, ,, Aunt, Augusta, ,, I, 'v...  Wilde"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df,\n",
    "                                         test_size=TEST_SIZE,\n",
    "                                         train_size=TRAIN_SIZE,\n",
    "                                         random_state=69,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"/home/julia/PycharmProjects/seq2seq/data/trainset_classification.csv\", index=False)\n",
    "test_df.to_csv(\"/home/julia/PycharmProjects/seq2seq/data/testset_classification.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50668, 2)\n",
      "(12668, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape) \n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_input(text):\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_input,\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LABEL = data.LabelField(dtype = torch.float)\n",
    " LABEL = data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/julia/PycharmProjects/seq2seq/data/'\n",
    "train = pd.read_csv(PATH+'trainset_classification_biclass.csv')\n",
    "validation = pd.read_csv(PATH+'testset_classification_biclass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = data.TabularDataset.splits(path='/home/julia/PycharmProjects/seq2seq/data/',\n",
    "                                                train = 'trainset_classification_biclass.csv',\n",
    "                                                validation = 'testset_classification_biclass.csv',\n",
    "                                                format='csv',\n",
    "                                                fields=[('input',SRC),('author',LABEL)],\n",
    "                                                skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34671"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': ['\"', 'his', 'pants', 'looked', 'mighty', 'like', 'billy', '.', '\"'],\n",
       " 'author': '0'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_set.examples[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AuthorClassification(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim,embed_matrix,hidden_dim, n_layers,n_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.embedding.weight.data.copy_(embed_matrix)\n",
    "        #self.embedding.weight.requires_grad = False ## freeze embeddings\n",
    "        self.lstm = nn.LSTM(embed_dim,hidden_dim,num_layers=n_layers)\n",
    "        self.linear = nn.Linear(hidden_dim,n_class)\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        #self.act = nn.Sigmoid()\n",
    "        #self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        x = self.dropout(embedded)\n",
    "        lstm_out,(h_t,c_t)=self.rnn(x)\n",
    "        return self.linear(h_t[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_Model(vocab_size, embed_dim,embed_matrix,hidden_dim, n_layers,n_class):\n",
    "    model = AuthorClassification(vocab_size,embed_dim,embed_matrix,hidden_dim,n_layers,n_class)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar modelo\n",
    "### Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion,clip_value,training = True):\n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    loss_sum = 0\n",
    "    #acc_sum = 0\n",
    " \n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        #acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        \n",
    "        if training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),clip_value)\n",
    "            optimizer.step()\n",
    "            \n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        #acc_sum+=acc\n",
    "        \n",
    "        \n",
    "        \n",
    "    epoch_loss = loss_sum / len(iterator)   \n",
    "    #ollasepoch_loss += loss.item()\n",
    "    #epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicio de Entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Crear vocabulario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_set,\n",
    "                         #dev_set,\n",
    "                         max_size = None,\n",
    "                         min_freq = 1,\n",
    "                         vectors = \"glove.6B.300d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_set,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEncoder embedding matrix: torch.Size([27594, 300])\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\tEncoder embedding matrix: {SRC.vocab.vectors.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "EMB_DIM = SRC.vocab.vectors.shape[1]\n",
    "HID_DIM = 512\n",
    "N_CLASSES=3\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EMB_MATIX = SRC.vocab.vectors\n",
    "PAD_IDX = SRC.vocab.stoi[SRC.pad_token] # padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, dev_iterator = BucketIterator.splits((train_set, test_set),\n",
    "                                        batch_size = BATCH_SIZE,\n",
    "                                        sort_within_batch = True,\n",
    "                                        #sort_key = lambda x: len(x.src), #attribute the text should be sorted\n",
    "                                        device = device,\n",
    "                                        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = INPUT_DIM\n",
    "embed_dim = EMB_DIM\n",
    "embed_matrix = EMB_MATIX\n",
    "hidden_dim = HID_DIM\n",
    "n_layers = N_LAYERS\n",
    "n_class = N_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_Model(vocab_size, embed_dim,embed_matrix,hidden_dim, n_layers,n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo tiene 12,048,059 de parámetros entrenables\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'El modelo tiene {get_number_parameters(model):,} de parámetros entrenables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = SRC.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(),lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'Example' and 'Example'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-e21944857607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                        \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                        \u001b[0mclip_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                        training = True)\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m#test_loss = evaluate(model, test_iterator, criterion)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"with torch.no_grad():\n",
      "\u001b[0;32m<ipython-input-104-d2fb1de1eb26>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip_value, training)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;31m# fast-forward if loaded from state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations_this_epoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mpool\u001b[0;34m(data, batch_size, key, batch_size_fn, random_shuffler, shuffle, sort_within_batch)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mp_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msort_within_batch\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'Example' and 'Example'"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "p = 1.0\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_loss_epoch = []\n",
    "test_loss_epoch = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    #p = max(min_prob, (p - linear_decay_num)) \n",
    "    start_time = time.time()\n",
    "    #train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    train_loss = train(model=model,\n",
    "                       iterator=train_iterator,\n",
    "                       #teacher_forcing_prob = p,\n",
    "                       optimizer=optimizer,\n",
    "                       criterion=criterion,\n",
    "                       clip_value=CLIP,\n",
    "                       training = True)\n",
    "    #test_loss = evaluate(model, test_iterator, criterion)\n",
    "    \"\"\"with torch.no_grad():\n",
    "        test_loss = train(model=model,\n",
    "                         iterator=test_iterator,\n",
    "                         optimizer=None,\n",
    "                         criterion=criterion,\n",
    "                         clip=CLIP)\n",
    "    \"\"\"\n",
    "    train_loss_epoch.append(train_loss)\n",
    "    #test_loss_epoch.append(test_loss)\n",
    "\n",
    "    #valid_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print('-' * 89)\n",
    "    print(f'Epoch: {epoch+1:03} | Time: {epoch_mins}m {epoch_secs}s | TFprob: {p:.4f} | Train loss: {train_loss:.4f} | ')\n",
    "print('-' * 89)\n",
    "\n",
    "    #if test_loss < best_valid_loss:\n",
    "    #    best_valid_loss = test_loss\n",
    "    #    torch.save(model.state_dict(), 'tut001-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator ,optimizer, criterion, clip):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src)\n",
    "        # trg = [trg len, batch size]\n",
    "        # output = [trg len, batch size, output dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg len - 1) * batch size]\n",
    "        # output = [(trg len - 1) * batch size, output dim]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
